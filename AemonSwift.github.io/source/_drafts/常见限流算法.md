---
title: 常见限流算法
tags:
- 算法
- 系统
categories:
- 系统
- 限流
toc: true
---
# 为什么需要限流算法
在高并发系统中，保护系统三大利器：缓存，降级，限流，即主要降低数据库的访问。当请求量超过系统负载的时候，为了保证系统正常运行，当请求达到一定的并发数或速率，就需要进行等待、排队、降级、拒绝服务等，从而保证了有效系统正常运行。
按照服务调用方分为如下几种类型
1. 与用户打交道服务
这类服务导致系统负载过高原因：
- 用户增长过快（好事）
- 某个热点事件（微博热搜）
- 竞争对象爬虫
- 恶意刷单
这类系统都是无法预知的，即弹性扩容根本不可能实现。
2. 对内的RPC服务
一个服务A的接口可能被B，C，D，E多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对C，D，E也无法提供服务。解决方案如下：a.每个调用方采用线程池进行资源隔离；b.使用限流手段对每个调用方进行限流。
# 常见的限流算法
计数器，令牌桶，漏桶，窗口等
## 计数器限流
主要用来限制总并发数，比如数据库连接池大小、线程池大小、程序访问并发数等都是使用计数器算法。
### 计数器限流示例——通过限制系统的并发调用程度来限流
例如go官方包里面httpServer频率限制，基本思路就是为连接数计数，通过make chan来建立一个最大连接数的channel, 每次accept就+1，close时候就-1. 当到达最大连接数时，就等待空闲连接出来之后再accept。
```go
package netutil // import "golang.org/x/net/netutil"
 
import (
    "net"
	"sync"
)
 
type limitListener struct {
	net.Listener
	sem       chan struct{}
	closeOnce sync.Once     // ensures the done chan is only closed once
	done      chan struct{} // no values sent; closed when Close is called
}

type limitListenerConn struct {
	net.Conn
	releaseOnce sync.Once
	release     func()
}
 
// LimitListener returns a Listener that accepts at most n simultaneous
// connections from the provided Listener.
func LimitListener(l net.Listener, n int) net.Listener {
	return &limitListener{
		Listener: l,
		sem:      make(chan struct{}, n),
		done:     make(chan struct{}),
	}
}
 
// acquire acquires the limiting semaphore. Returns true if successfully
// accquired, false if the listener is closed and the semaphore is not
// acquired.
func (l *limitListener) acquire() bool {
	select {
	case <-l.done:
		return false
	case l.sem <- struct{}{}:
		return true
	}
}
func (l *limitListener) release() { <-l.sem }
 
func (l *limitListener) Accept() (net.Conn, error) {
    //如果sem满了，就会阻塞在这
	acquired := l.acquire()
	// If the semaphore isn't acquired because the listener was closed, expect
	// that this call to accept won't block, but immediately return an error.
	c, err := l.Listener.Accept()
	if err != nil {
		if acquired {
			l.release()
		}
		return nil, err
	}
	return &limitListenerConn{Conn: c, release: l.release}, nil
}
 
func (l *limitListener) Close() error {
	err := l.Listener.Close()
	l.closeOnce.Do(func() { close(l.done) })
	return err
}
 
func (l *limitListenerConn) Close() error {
	err := l.Conn.Close()
    //close时释放占用的sem
	l.releaseOnce.Do(l.release)
	return err
}
```
使用count进行统计当前正在并发执行的次数，如果超过域值就简单粗暴的直接响应给用户，说明系统繁忙，请稍后再试或其它跟业务相关的信息。
$\color{red}{弊端：}$使用count简单粗暴超过域值就拒绝请求，可能只是瞬时的请求量高，也会拒绝请求。
### 计数器限流示例2——通过限制单位时间段内调用量来限流
上述方法简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。
```go
type AbandonReqLimitService struct {
    Interval time.Duration // 设置计数器的时间间隔
    MaxCount int // 计数器的最大值
    Lock     sync.Mutex // 锁
    ReqCount int // 计数器
}

func CreateAbandonReqLimitService(interval time.Duration, maxCount int) *AbandonReqLimitService {
    reqLimit := &AbandonReqLimitService{
        Interval: interval,
        MaxCount: maxCount,
    }
    go func() { // 开启一个go协程来定时更新计数器
        ticker := time.NewTicker(interval) // go中的定时器
        for {
            <-ticker.C
            reqLimit.Lock.Lock()
            reqLimit.ReqCount = 0
            reqLimit.Lock.Unlock()
        }
    }()
    return reqLimit
}

func (reqLimit *AbandonReqLimitService) GetTokenAbandonRequest() bool { // 取令牌函数
    reqLimit.Lock.Lock()
    defer reqLimit.Lock.Unlock()
    if reqLimit.ReqCount < reqLimit.MaxCount {
        reqLimit.ReqCount += 1
        return true
    } else {
        return false
    }
}
```
$\color{red}{弊端：}$如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能请求拒绝，我们把这种现象称为“突刺现象”.
### 计数器限流示例3——采用队列的形式
形式类似信号量Semaphore。
```go
type SemaphoreService struct {
	Semaphore chan struct{}
}

func CreateSemaphore(maxCnt int) chan struct{}{
	return make(chan struct{},maxCnt)
}

func(semaphore *SemaphoreService)Accquire(){
	semaphore.Semaphore<-struct{}{}
}

func (semaphore *SemaphoreService) Release(){
	<-semaphore.Semaphore
}
```
如果是瞬时的高并发，可以使请求在阻塞队列中排队，而不是马上拒绝请求，从而达到一个流量削峰的目的。$\color{red}{但无法应对短时间的突发流量。}
## 漏桶限流
为了消除"突刺现象"，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。
漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。
不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。
```go
package ratelimiter

import (
	"sync"
	"time"
)

type rateLimiter struct {
	lck      *sync.Mutex
	rate     float64   //最大速率限制
	balance  float64   //漏桶的余量
	limit    float64   //漏桶的最大容量限制
	lastTime time.Time //上次检查的时间
}

func NewRateLimiter(limitPerSecond int, balance int) *rateLimiter {
	return &rateLimiter{
		lck:      new(sync.Mutex),
		rate:     float64(limitPerSecond),
		balance:  float64(balance),
		limit:    float64(balance),
		lastTime: time.Now(),
	}
}

func (r *rateLimiter) Check() bool {
	ok := false
	r.lck.Lock()
	now := time.Now()
	dur := now.Sub(r.lastTime).Seconds()
	r.lastTime = now
	water := dur * r.rate //计算这段时间内漏桶流出水的流量water
	r.balance += water    //漏桶流出water容量的水，自然漏桶的余量多出water
	if r.balance > r.limit {
		r.balance = r.limit
	}
	if r.balance >= 1 { //漏桶余量足够容下当前的请求
		r.balance -= 1
		ok = true
	}
	r.lck.Unlock()
	return ok
}

//单元测试
package ratelimiter

import (
	"fmt"
	"testing"
	"time"
)

func TestRateLimiter_Check(t *testing.T) {
	limiter := NewRateLimiter(10, 1)
	start := time.Now()
	count := 0
	for i := 0; i < 1e3; i++ {
		if limiter.Check() {
			fmt.Println(i)
			count++
		}
		time.Sleep(time.Millisecond)
	}
	fmt.Println("count:", count)
	fmt.Println(time.Now().Sub(start).Seconds())
}
```
漏桶算法能够强行限制数据的传输速率，$\color{blue}{但无法应对短时间的突发流量}$。

## 令牌桶限流
从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。
令牌桶算法（Token Bucket）：是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。
在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。
放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。
一个简单的实现：利用的就是channel的阻塞操作。
我们把一个指定尺寸channel，相当于一个指定容量的令牌桶，每一个空闲位置就是一个令牌。由于channel满时就无法向其中加元素，所以我们就可以以固定的速率消费channel中的消息（释放空间相当于添加令牌），取令牌就是添加一条消息，当令牌桶满时就无法正常添加消息（取令牌）了，这样就利用channel来构造了一个限流器。
```go
type NotAbandonReqLimitService struct {
    TokenPool chan bool // 令牌桶
}
func CreateNewRequestLimitService(interval time.Duration, maxCnt int) *NotAbandonReqLimitService {
    reqLimit := &NotAbandonReqLimitService{}
    reqLimit.TokenPool = make(chan bool, maxCnt) // 令牌桶最大容量
    go func() {
        tmpStr := strconv.Itoa(maxCnt)
        maxCntInt64,_ := strconv.ParseInt(tmpStr, 10, 64)
        ticker := time.NewTicker( time.Duration(interval.Nanoseconds()/(maxCntInt64*1000*1000))* time.Millisecond) // 匀速添加令牌，1s/最大qps 就是添加的速率
        for {
            <- ticker.C
            <- reqLimit.TokenPool
        }
    }()
    return reqLimit
}
func (reqLimit *NotAbandonReqLimitService) GetTokenNotAbandonRequest() {
    reqLimit.TokenPool <- true // 消费令牌
}
```
例如go官方包rate，其思想为：用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中），桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃；
```go
package rate
 
import (
	"fmt"
	"math"
	"sync"
	"time"
 
	"golang.org/x/net/context"
)
 
// Limit defines the maximum frequency of some events.
// Limit is represented as number of events per second.
// A zero Limit allows no events.
type Limit float64
 
// Inf is the infinite rate limit; it allows all events (even if burst is zero).
const Inf = Limit(math.MaxFloat64)
 
// Every converts a minimum time interval between events to a Limit.
func Every(interval time.Duration) Limit {
	if interval <= 0 {
		return Inf
	}
	return 1 / Limit(interval.Seconds())
}
 
// A Limiter controls how frequently events are allowed to happen.
// It implements a "token bucket" of size b, initially full and refilled
// at rate r tokens per second.
// Informally, in any large enough time interval, the Limiter limits the
// rate to r tokens per second, with a maximum burst size of b events.
// As a special case, if r == Inf (the infinite rate), b is ignored.
// See https://en.wikipedia.org/wiki/Token_bucket for more about token buckets.
//
// The zero value is a valid Limiter, but it will reject all events.
// Use NewLimiter to create non-zero Limiters.
//
// Limiter has three main methods, Allow, Reserve, and Wait.
// Most callers should use Wait.
//
// Each of the three methods consumes a single token.
// They differ in their behavior when no token is available.
// If no token is available, Allow returns false.
// If no token is available, Reserve returns a reservation for a future token
// and the amount of time the caller must wait before using it.
// If no token is available, Wait blocks until one can be obtained
// or its associated context.Context is canceled.
//
// The methods AllowN, ReserveN, and WaitN consume n tokens.
type Limiter struct {
	//maximum token, token num per second
	limit Limit
	//burst field, max token num
	burst int
	mu    sync.Mutex
	//tokens num, change
	tokens float64
	// last is the last time the limiter's tokens field was updated
	last time.Time
	// lastEvent is the latest time of a rate-limited event (past or future)
	lastEvent time.Time
}
 
// Limit returns the maximum overall event rate.
func (lim *Limiter) Limit() Limit {
	lim.mu.Lock()
	defer lim.mu.Unlock()
	return lim.limit
}
 
// Burst returns the maximum burst size. Burst is the maximum number of tokens
// that can be consumed in a single call to Allow, Reserve, or Wait, so higher
// Burst values allow more events to happen at once.
// A zero Burst allows no events, unless limit == Inf.
func (lim *Limiter) Burst() int {
	return lim.burst
}
 
// NewLimiter returns a new Limiter that allows events up to rate r and permits
// bursts of at most b tokens.
func NewLimiter(r Limit, b int) *Limiter {
	return &Limiter{
		limit: r,
		burst: b,
	}
}
 
// Allow is shorthand for AllowN(time.Now(), 1).
func (lim *Limiter) Allow() bool {
	return lim.AllowN(time.Now(), 1)
}
 
// AllowN reports whether n events may happen at time now.
// Use this method if you intend to drop / skip events that exceed the rate limit.
// Otherwise use Reserve or Wait.
func (lim *Limiter) AllowN(now time.Time, n int) bool {
	return lim.reserveN(now, n, 0).ok
}
 
// A Reservation holds information about events that are permitted by a Limiter to happen after a delay.
// A Reservation may be canceled, which may enable the Limiter to permit additional events.
type Reservation struct {
	ok     bool
	lim    *Limiter
	tokens int
	//This is the time to action
	timeToAct time.Time
	// This is the Limit at reservation time, it can change later.
	limit Limit
}
 
// OK returns whether the limiter can provide the requested number of tokens
// within the maximum wait time.  If OK is false, Delay returns InfDuration, and
// Cancel does nothing.
func (r *Reservation) OK() bool {
	return r.ok
}
 
// Delay is shorthand for DelayFrom(time.Now()).
func (r *Reservation) Delay() time.Duration {
	return r.DelayFrom(time.Now())
}
 
// InfDuration is the duration returned by Delay when a Reservation is not OK.
const InfDuration = time.Duration(1<<63 - 1)
 
// DelayFrom returns the duration for which the reservation holder must wait
// before taking the reserved action.  Zero duration means act immediately.
// InfDuration means the limiter cannot grant the tokens requested in this
// Reservation within the maximum wait time.
func (r *Reservation) DelayFrom(now time.Time) time.Duration {
	if !r.ok {
		return InfDuration
	}
	delay := r.timeToAct.Sub(now)
	if delay < 0 {
		return 0
	}
	return delay
}
 
// Cancel is shorthand for CancelAt(time.Now()).
func (r *Reservation) Cancel() {
	r.CancelAt(time.Now())
	return
}
 
// CancelAt indicates that the reservation holder will not perform the reserved action
// and reverses the effects of this Reservation on the rate limit as much as possible,
// considering that other reservations may have already been made.
func (r *Reservation) CancelAt(now time.Time) {
	if !r.ok {
		return
	}
	r.lim.mu.Lock()
	defer r.lim.mu.Unlock()
	if r.lim.limit == Inf || r.tokens == 0 || r.timeToAct.Before(now) {
		return
	}
	// calculate tokens to restore
	// The duration between lim.lastEvent and r.timeToAct tells us how many tokens were reserved
	// after r was obtained. These tokens should not be restored.
	restoreTokens := float64(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct))
	if restoreTokens <= 0 {
		return
	}
	// advance time to now
	now, _, tokens := r.lim.advance(now)
	// calculate new number of tokens
	tokens += restoreTokens
	if burst := float64(r.lim.burst); tokens > burst {
		tokens = burst
	}
	// update state
	r.lim.last = now
	r.lim.tokens = tokens
	if r.timeToAct == r.lim.lastEvent {
		prevEvent := r.timeToAct.Add(r.limit.durationFromTokens(float64(-r.tokens)))
		if !prevEvent.Before(now) {
			r.lim.lastEvent = prevEvent
		}
	}
	return
}
 
// Reserve is shorthand for ReserveN(time.Now(), 1).
func (lim *Limiter) Reserve() *Reservation {
	return lim.ReserveN(time.Now(), 1)
}
 
// ReserveN returns a Reservation that indicates how long the caller must wait before n events happen.
// The Limiter takes this Reservation into account when allowing future events.
// ReserveN returns false if n exceeds the Limiter's burst size.
// Usage example:
//   r, ok := lim.ReserveN(time.Now(), 1)
//   if !ok {
//     // Not allowed to act! Did you remember to set lim.burst to be > 0 ?
//   }
//   time.Sleep(r.Delay())
//   Act()
// Use this method if you wish to wait and slow down in accordance with the rate limit without dropping events.
// If you need to respect a deadline or cancel the delay, use Wait instead.
// To drop or skip events exceeding rate limit, use Allow instead.
func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation {
	r := lim.reserveN(now, n, InfDuration)
	return &r
}
 
// Wait is shorthand for WaitN(ctx, 1).
func (lim *Limiter) Wait(ctx context.Context) (err error) {
	return lim.WaitN(ctx, 1)
}
 
// WaitN blocks until lim permits n events to happen.
// It returns an error if n exceeds the Limiter's burst size, the Context is
// canceled, or the expected wait time exceeds the Context's Deadline.
func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) {
	if n > lim.burst {
		return fmt.Errorf("rate: Wait(n=%d) exceeds limiter's burst %d", n, lim.burst)
	}
	// Check if ctx is already cancelled
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
	}
	// Determine wait limit
	now := time.Now()
	waitLimit := InfDuration
	if deadline, ok := ctx.Deadline(); ok {
		waitLimit = deadline.Sub(now)
	}
	// Reserve
	r := lim.reserveN(now, n, waitLimit)
	if !r.ok {
		return fmt.Errorf("rate: Wait(n=%d) would exceed context deadline", n)
	}
	// Wait
	t := time.NewTimer(r.DelayFrom(now))
	defer t.Stop()
	select {
	case <-t.C:
		// We can proceed.
		return nil
	case <-ctx.Done():
		// Context was canceled before we could proceed.  Cancel the
		// reservation, which may permit other events to proceed sooner.
		r.Cancel()
		return ctx.Err()
	}
}
 
// SetLimit is shorthand for SetLimitAt(time.Now(), newLimit).
func (lim *Limiter) SetLimit(newLimit Limit) {
	lim.SetLimitAt(time.Now(), newLimit)
}
 
// SetLimitAt sets a new Limit for the limiter. The new Limit, and Burst, may be violated
// or underutilized by those which reserved (using Reserve or Wait) but did not yet act
// before SetLimitAt was called.
func (lim *Limiter) SetLimitAt(now time.Time, newLimit Limit) {
	lim.mu.Lock()
	defer lim.mu.Unlock()
	now, _, tokens := lim.advance(now)
	lim.last = now
	lim.tokens = tokens
	lim.limit = newLimit
}
 
// reserveN is a helper method for AllowN, ReserveN, and WaitN.
// maxFutureReserve specifies the maximum reservation wait duration allowed.
// reserveN returns Reservation, not *Reservation, to avoid allocation in AllowN and WaitN.
func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation {
	lim.mu.Lock()
	defer lim.mu.Unlock()
	if lim.limit == Inf {
		return Reservation{
			ok:        true,
			lim:       lim,
			tokens:    n,
			timeToAct: now,
		}
	}
	now, last, tokens := lim.advance(now)
	// Calculate the remaining number of tokens resulting from the request.
	tokens -= float64(n)
	// Calculate the wait duration
	var waitDuration time.Duration
	if tokens < 0 {
		waitDuration = lim.limit.durationFromTokens(-tokens)
	}
	// Decide result
	ok := n <= lim.burst && waitDuration <= maxFutureReserve
	// Prepare reservation
	r := Reservation{
		ok:    ok,
		lim:   lim,
		limit: lim.limit,
	}
	if ok {
		r.tokens = n
		r.timeToAct = now.Add(waitDuration)
	}
	// Update state
	if ok {
		lim.last = now
		lim.tokens = tokens
		lim.lastEvent = r.timeToAct
	} else {
		lim.last = last
	}
	return r
}
 
// advance calculates and returns an updated state for lim resulting from the passage of time.
// lim is not changed.
func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) {
	last := lim.last
	if now.Before(last) {
		last = now
	}
	// Avoid making delta overflow below when last is very old.
	maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens)
	elapsed := now.Sub(last)
	if elapsed > maxElapsed {
		elapsed = maxElapsed
	}
	// Calculate the new number of tokens, due to time that passed.
	delta := lim.limit.tokensFromDuration(elapsed)
	tokens := lim.tokens + delta
	if burst := float64(lim.burst); tokens > burst {
		tokens = burst
	}
	return now, last, tokens
}
 
// durationFromTokens is a unit conversion function from the number of tokens to the duration
// of time it takes to accumulate them at a rate of limit tokens per second.
func (limit Limit) durationFromTokens(tokens float64) time.Duration {
	seconds := tokens / float64(limit)
	return time.Nanosecond * time.Duration(1e9*seconds)
}
 
// tokensFromDuration is a unit conversion function from a time duration to the number of tokens
// which could be accumulated during that duration at a rate of limit tokens per second.
func (limit Limit) tokensFromDuration(d time.Duration) float64 {
	return d.Seconds() * float64(limit)
}
```
虽然在某些情况下使用单个全局速率限制器非常有用，但另一种常见情况是基于IP地址或API密钥等标识符为每个用户实施速率限制器。我们将使用IP地址作为标识符。简单实现代码如下：
```go
package main
import (
    "net/http"
    "sync"
    "time"
    "golang.org/x/time/rate"
)
// Create a custom visitor struct which holds the rate limiter for each
// visitor and the last time that the visitor was seen.
type visitor struct {
    limiter  *rate.Limiter
    lastSeen time.Time
}
// Change the the map to hold values of the type visitor.
var visitors = make(map[string]*visitor)
var mtx sync.Mutex
// Run a background goroutine to remove old entries from the visitors map.
func init() {
    go cleanupVisitors()
}
func addVisitor(ip string) *rate.Limiter {
    limiter := rate.NewLimiter(2, 5)
    mtx.Lock()
    // Include the current time when creating a new visitor.
    visitors[ip] = &visitor{limiter, time.Now()}
    mtx.Unlock()
    return limiter
}
func getVisitor(ip string) *rate.Limiter {
    mtx.Lock()
    v, exists := visitors[ip]
    if !exists {
        mtx.Unlock()
        return addVisitor(ip)
    }
    // Update the last seen time for the visitor.
    v.lastSeen = time.Now()
    mtx.Unlock()
    return v.limiter
}
// Every minute check the map for visitors that haven't been seen for
// more than 3 minutes and delete the entries.
func cleanupVisitors() {
    for {
        time.Sleep(time.Minute)
        mtx.Lock()
        for ip, v := range visitors {
            if time.Now().Sub(v.lastSeen) > 3*time.Minute {
                delete(visitors, ip)
            }
        }
        mtx.Unlock()
    }
}
func limit(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        limiter := getVisitor(r.RemoteAddr)
        if limiter.Allow() == false {
            http.Error(w, http.StatusText(429), http.StatusTooManyRequests)
            return
        }
        next.ServeHTTP(w, r)
	})
}
```
## 窗口限流
### Fixed Window
固定窗口算法，设置一个时间段内（窗口）接收的请求数，超过的这个请求数的请求会被丢弃。
- 窗口通常选择人们熟悉的时间段：1 分钟／1小时
- 窗口的起始时间通常是当前时间取地板（floor），比如 12:00:03 所在的窗口 （以一分钟的窗口为例）就是 12:00:00 - 12:01:00
和漏桶相比，能够让新来的请求也能够被处理到，但存在缺点：
- 在窗口的起始时间，最差情况下可能会带来 2 倍的流量
- 很多消费者可能都在等待窗口被重置，造成惊群效应（惊群效应：当某一资源可用时，n个进程/线程会惊醒，竞争资源。导致n-1个进程/线程做了无效的调度,上下文切换，cpu瞬时增高）
### Sliding Log
滑动日志算法，利用记录下来的用户的请求时间，请求数，当该用户的一个新的 请求进来时，比较这个用户在这个窗口内的请求数是否超过了限定值，超过的话 就拒绝这个请求。
优点：
- 避免了固定窗口算法在窗口边界可能出现的两倍流量问题
- 由于是针对每个用户进行统计的，不会引发惊群效应
缺点：
- 需要保存大量的请求日志
- 每个请求都需要考虑该用户之前的请求情况，在分布式系统中尤其难做到
### Sliding Window
滑动窗口算法，结合了固定窗口算法的低开销和滑动日志算法能够解决的边界情况。
- 为每个窗口进行请求量的计数
- 结合上一个窗口的请求量和这一个窗口已经经过的时间来计算出上限，以此 平滑请求尖锋
举例来说，限流的上限是每分钟 10 个请求，窗口大小为 1 分钟，上一个 窗口中总共处理了 6 个请求。现在假设这个新的窗口已经经过了 20 秒，那么 到目前为止允许的请求上限就是 `10 - 6 * (1 - 20 / 60) = 8`。
滑动窗口算法是这些算法中最实用的算法：
- 避免了漏桶算法带来的饥饿问题
- 避免了固定窗口算法的请求量突增的问题


## 集群限流
上述限流方法都是单机限流的范畴，比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。
难点在于限流上限都是针对全站的流量设置的，那么每个节点该如何协调各自处理的量呢？
### 同步的策略
解决的方法通常都是使用一个统一的数据库来存放计数，比如 Redis 或者 Cassandra。 数据库中将存放每个窗口和用户的计数值。这种方法的主要问题是需要多访问一次数据库， 以及竞争问题。
### 竞争问题
竞争问题就是当有两个以上的线程同时执行 i += 1 的时候，如果没有同步这 些操作的话，i 的值可能会有多种情况。
处理竞争问题可以通过加锁来做，不过在限流的场景下，这样做肯定会成为系统的瓶颈， 毕竟限流时每个请求都会来竞争这个锁。
更好的办法是通过 set-then-get 的方法，限流场景中用到的只是计数 +1， 利用这一点以及数据库实现的性能更好的原子操作可以达到我们的目的。
### 性能优化
利用集中式的数据库的另一个问题是每次请求都要查一下数据库带来的延迟开销， 数据库再快也会带来几毫秒的延迟。
解决这个问题的方法可以通过在内存里面维护一个计数值，代价是稍微的放松限 流的精确度。通过设置一个定时任务从数据库拿计数值，周期内在内存中维护这 个计数，周期结束时把计数同步到数据库并拿取新的计数，如此往复。
这个同步周期往往是做成可以配置的，小的周期能够带来更精确的限流， 大的周期则能减轻数据库的 I/O 压力。
# 参考文献
[基于令牌桶算法和漏桶算法来实现的限速限流](https://github.com/yangwenmai/ratelimit)
[轻量级限流中间件](https://github.com/didip/tollbooth)
[漏桶算法&令牌桶算法理解及常用的算法](https://www.jianshu.com/p/c02899c30bbd)
[go channel实现简单信号量](https://blog.csdn.net/qq_15437667/article/details/70769084)
[go语言生产者消费者信号量实现](https://blog.csdn.net/qq_30505673/article/details/82156834)
[Golang实现请求限流的几种办法](https://blog.csdn.net/micl200110041/article/details/82013032)
[高并发系统限流-漏桶算法和令牌桶算法](https://blog.csdn.net/weixin_42296449/article/details/90318706)
[谈谈服务限流算法的几种实现](https://blog.csdn.net/linhui258/article/details/81155622)
[常用的限流算法](https://www.cnblogs.com/senlinyang/p/7840304.html)
[高并发系统限流中的漏桶算法和令牌桶算法，通过流量整形和速率限制提升稳定性](https://blog.csdn.net/scorpio3k/article/details/53103239)
[高并发系统限流中的算法](https://blog.csdn.net/u012526691/article/details/80333907)
[限流算法比较与实现](https://www.jianshu.com/p/ee2c8843f7a9)
[接口限流算法（关于临界点处理）](https://blog.csdn.net/ljj821061514/article/details/52512943)
[限流算法的理解和应用场景和实现](https://blog.csdn.net/u010963948/article/details/79424413)
[高并发中的惊群效应](https://blog.csdn.net/second60/article/details/81252106)
