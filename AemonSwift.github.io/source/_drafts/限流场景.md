---
title: 限流手段——接入层，应用级，分布式限流
tags:
- 系统
categories:
- 系统
- 限流
toc: true
---

在开发高并发的系统时，有很多手段来保护系统，如缓存、降级和限流等。缓存可以提升系统的访问速度，降级可以暂时屏蔽掉非核心业务，使得核心业务不受影响。限流的目的通过对并发访问进行限速，一旦达到一定的速率就可以`拒绝服务`（定向到错误页或告知资源没有了）、`排队等待`（如秒杀、评论、下单等）、`降级`（直接返回兜底数据、如商品库存默认有货）。
限流即流量限制，或者高大上一点，叫做流量整形，限流的目的是在遇到流量高峰期或者流量突增（流量尖刺）时，把流量速率限制在系统所能接受的合理范围之内，不至于让系统被高流量击垮。
其实，服务降级系统中的限流并没有我们想象的那么简单，第一，限流方案必须是可选择的，没有任何方案可以适用所有场景，每种限流方案都有自己适合的场景，我们得根据业务和资源的特性和要求来选择限流方案；第二，限流策略必须是可配的，对策略调优一定是个长期的过程，这里说的策略，可以理解成建立在某个限流方案上的一套相关参数。
常见的限流方式有：`限制总并发数`（数据库连接池、线程池）、`限制瞬时并发数`（如Nginx的limit_conn模块）、`限制时间窗口的平均速率`（如Guava的RateLimiter、Nginx的limit_req模块）、`限制远程接口的调用速率`、`限制MQ的消费速率`等。从应用的层面上来讲，又可以分为：`接入层限流`、`应用层限流`和`分布式限流`等。
# 接入层限流
接入层目的是负载均衡，非法请求过滤，请求聚合，缓存，降级，限流，A/B测试，服务质量监控等。
对于Nginx接入层限流可以使用Nginx自带的两个模块：基于计数器实现连接数限流模块`ngx_http_limit_conn_module`和漏桶算法实现的请求限流模块`ngx_http_limit_req_module`。还可以使用OpenResty提供的Lua限流模块`lua-resty-limit-traffic`进行更复杂的限流场景。
## ngx_http_limit_conn_module
连接数限流模块，和一般的计数器限流是一样的思路，通过一个key来存取对应的value，value表示请求的数量。比如：限制某个IP的总请求数量，那么我们只需要改变和存取该IP对应的请求数量即可。
```
http{
    limit_conn_zone $binary_remote_addr zone=perip:10m;
    limit_conn_zone $server_name zone=perserver:10m;
    limit_conn_log_level error;
    limit_conn_status 503;
    ...
    server{
        ...
        location /limit{
            limit_conn perip 1; #限制单个IP同时最多能持有1个连接
            limit_conn perserver 100; # 限制Server的最大连接数
            proxy_pass ‘http:www.baidu.com‘; #未被限流的去的地址
        }    
    }  
}
```
1. limit_conn：配置的是要存放KEY和计数器的共享内存区域，并指定KEY的最大连接数目（这里是1）
2. limit_conn_zone: 配置限流的KEY（这里是IP地址：$binary_remote_addr）、共享内存区域的大小(10m)。
3. limit_conn_status: 配置限流以后返回的状态码；
4. limit_conn_log_level: 配置限流以后的日志级别；
5. proxy_pass: 返回代理的是百度的页面；
### limit_conn的主要执行过程
1. 请求进入首先判断当前limit_conn_zone中相应的key的连接数是否超出了配置的最大链接数 
2. 请求进入首先判断当前limit_conn_zone中相应的key的连接数是否超出了配置的最大链接数 
3. 进行请求处理 
4. 结束请求阶段会调用注册的回调函数对相应的链接数减1

## ngx_http_limit_req_module
请求限流模块实现的是漏桶算法，主要是对请求的速率进行限制。
```
http {
    limit_req_zone $binary_remote_addr zone=serviceRateLimit:10m rate=1r/s;
    limit_conn_log_level error;
    limit_conn_status 503;
    ...
    server {
    ...
        location /limit {
            limit_req zone=serviceRateLimit burst=2 nodelay; # 桶大小用于突发流量配置
            proxy_pass: ‘http://www.baidu.com‘;
        }
    }
}
```
1. limit_req：配置共享内存区域（serviceRateLimit）、桶容量（突发容量，默认0，目前配置为2）、是否延迟模式（默认延迟）
2. limit_req_zone：配置限流KEY、及存放KEY对应信息的共享内存区域大小、固定请求速率；此处指定的KEY是“$binary_remote_addr”表示IP地址；固定请求速率使用rate参数配置，支持10r/s和60r/m，即每秒10个请求和每分钟60个请求，不过最终都会转换为每秒的固定请求速率（10r/s为每100毫秒处理一个请求；60r/m，即每1000毫秒处理一个请求）。
3. limit_conn_status：配置被限流后返回的状态码，默认返回503；
4. limit_conn_log_level：配置记录被限流后的日志级别，默认error级别。
### limit_req主要执行过程
1. 请求进入后首先判断最后一次请求时间相对于当前时间（第一次是0）是否需要限流，如果需要限流则执行步骤2，否则执行步骤3；
2.1 如果没有配置桶容量（burst），则桶容量为0；按照固定速率处理请求；如果请求被限流，则直接返回相应的错误码（默认503）；
2.2 如果配置了桶容量（burst>0）且延迟模式(没有配置nodelay)；如果桶满了，则新进入的请求被限流；如果没有满则请求会以固定平均速率被处理（按照固定速率并根据需要延迟处理请求，延迟使用休眠实现）；
2.3 如果配置了桶容量（burst>0）且非延迟模式（配置了nodelay）；不会按照固定速率处理请求，而是允许突发处理请求；如果桶满了，则请求被限流，直接返回相应的错误码；
3. 如果没有被限流，则正常处理请求；
4. Nginx会在相应时机进行选择一些（3个节点）限流KEY进行过期处理，进行内存回收。
## OpenResty实现的限流
后续补充......

# 应用级限流
##  限制总并发数/连接/请求数
如果有的资源是稀缺资源（如数据库连接、线程），而且可能有多个系统都会去使用它，那么需要限制应用；可以使用池化技术来限制总资源数：连接池、线程池。比如分配给每个应用的数据库连接是100，那么本应用最多可以使用100个资源，超出了可以等待或者抛异常。
对于一个应用来说，总会有一个TPS/QPS的阀值，如果超过了阀值，则系统就会变得非常慢跟甚至无法响应。因此需要对系统进行过载保护，避免大量请求击垮系统。
如Tomcat的Connector中的以下几个参数：
- acceptCount：如果Tomcat的线程都忙于响应，新来的连接将会进入队列，如果超出队列大小，则会拒绝连接。
- maxConnections：瞬时最大连接数，超出的会排队等待。
- maxThreads：Tomcat能启动用来处理请求的最大线程数，如果请求处理量一直远远大于线程数，则会引起响应变慢甚至会僵死。
类似于Tomcat配置最大连接数等参数，Redis和MySQL也有相关的配置。
## 限制接口的总并发/请求数
如果接口可能会有突发访问情况，但又担心访问量太大造成崩溃，如抢购业务；这个时候就需要限制这个接口的总并发/请求数总请求数了；因为粒度比较细，可以为每个接口都设置相应的阀值。
这种方式实现起来比较简单暴力，没有平滑处理，这需要根据实际情况选择使用。
## 限流接口每秒的请求数
即一个时间窗口内的请求数，如想限制某个接口/服务每秒/每分钟/每天的请求数/调用量。如一些基础服务会被很多其他系统调用，比如商品详情页服务会调用基础商品服务调用，但是怕因为更新量比较大将基础服务打挂，这时我们要对每秒/每分钟的调用量进行限速；
## 平滑限流接口的请求数
之前的限流方式都不能很好地应对突发请求，即瞬间请求可能都被允许从而导致一些问题；因此在一些场景中需要对突发请求进行整形，整形为平均速率请求处理（比如5r/s，则每隔200毫秒处理一个请求，平滑了速率）。这个时候有两种算法满足我们的场景：令牌桶和漏桶算法。
## 平滑突发限流
平滑突发限流顾名思义，就是允许突发的流量进入，后面再慢慢的平稳限流。令牌桶算法
## 平滑预热限流
平滑突发限流有可能瞬间带来了很大的流量，如果系统扛不住的话，很容易造成系统挂掉。这时候，平滑预热限流便可以解决这个问题。令牌桶算法。
```
// permitsPerSecond表示每秒钟新增的令牌数，warmupPeriod表示从冷启动速率过渡到平均速率所需要的时间间隔
RateLimiter.create(double permitsPerSecond, long warmupPeriod, TimeUnit unit)
RateLimiter limiter = RateLimiter.create(5, 1000, TimeUnit.MILLISECONDS);
for (int i = 1; i < 5; i++) {
    System.out.println(limiter.acquire());
}
Thread.sleep(1000L);
for (int i = 1; i < 50; i++) {
    System.out.println(limiter.acquire());
}
```
# 分布式限流
分布式限流最关键的是要将限流服务做成原子化，而解决方案可以使使用redis+lua或者nginx+lua技术进行实现，通过这两种技术可以实现的高并发和高性能。
首先我们来使用redis+lua实现时间窗内某个接口的请求数限流，实现了该功能后可以改造为限流总并发/请求数和限制总资源数。Lua本身就是一种编程语言，也可以使用它实现复杂的令牌桶或漏桶算法。
# 参考文献
[常用限流方案的设计和实现](https://www.cnblogs.com/549294286/p/7726046.html)
[OpenResty提供的Lua限流模块lua-resty-limit-traffic](https://github.com/openresty/lua-resty-limit-traffic/blob/master/lib/resty/limit/req.md)
[OpenResty实现限流的几种方式](https://blog.51cto.com/zhweizhi/2063157)
[高并发限流+分布式限流](https://www.cnblogs.com/the-fool/p/11054072.html)
[聊聊高并发系统之限流特技-1](https://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&mid=2652897781&idx=1&sn=ae121ce4c3c37b7158bc9f067fa024c0)